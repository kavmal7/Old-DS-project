{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this file, we will model, fit, and select the ideal machine learning model for the data we prepared during preparation in the file preparation.ipynb."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will obviously need numpy and pandas to manage the data as usual, but we will also make use of sklearn's various modules for constructing models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from sklearn.dummy import DummyRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import LinearRegression, Lasso, ElasticNet\n",
    "from sklearn.preprocessing import PolynomialFeatures, MinMaxScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We had saved the training, validation, and test data in csv files during preparation, so we can use them here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dato/Tid           object\n",
       "Volum               int64\n",
       "Solskinstid       float64\n",
       "Lufttemperatur    float64\n",
       "Vindstyrke        float64\n",
       "Måned               int64\n",
       "Dag                 int64\n",
       "Ukedag              int64\n",
       "Time                int64\n",
       "Måned_1             int64\n",
       "Måned_10            int64\n",
       "Måned_11            int64\n",
       "Måned_12            int64\n",
       "Måned_2             int64\n",
       "Måned_3             int64\n",
       "Måned_4             int64\n",
       "Måned_5             int64\n",
       "Måned_6             int64\n",
       "Måned_7             int64\n",
       "Måned_8             int64\n",
       "Måned_9             int64\n",
       "Ukedag_0            int64\n",
       "Ukedag_1            int64\n",
       "Ukedag_2            int64\n",
       "Ukedag_3            int64\n",
       "Ukedag_4            int64\n",
       "Ukedag_5            int64\n",
       "Ukedag_6            int64\n",
       "Time_0              int64\n",
       "Time_1              int64\n",
       "Time_10             int64\n",
       "Time_11             int64\n",
       "Time_12             int64\n",
       "Time_13             int64\n",
       "Time_14             int64\n",
       "Time_15             int64\n",
       "Time_16             int64\n",
       "Time_17             int64\n",
       "Time_18             int64\n",
       "Time_19             int64\n",
       "Time_2              int64\n",
       "Time_20             int64\n",
       "Time_21             int64\n",
       "Time_22             int64\n",
       "Time_23             int64\n",
       "Time_3              int64\n",
       "Time_4              int64\n",
       "Time_5              int64\n",
       "Time_6              int64\n",
       "Time_7              int64\n",
       "Time_8              int64\n",
       "Time_9              int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reading in our saved CSV files\n",
    "data_train = pd.read_csv('data_train.csv')\n",
    "data_val = pd.read_csv('data_val.csv')\n",
    "data_test = pd.read_csv('data_test.csv')\n",
    "target_2022 = pd.read_csv('target_2022.csv')\n",
    "\n",
    "data_train.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the datetime object was converted from \"datetime\" to \"object\" during conversion to CSV, we need to convert that column back to datetime."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train['Dato/Tid'] = pd.to_datetime(data_train['Dato/Tid'])\n",
    "data_val['Dato/Tid'] = pd.to_datetime(data_val['Dato/Tid'])\n",
    "data_test['Dato/Tid'] = pd.to_datetime(data_test['Dato/Tid'])\n",
    "\n",
    "target_2022['Dato/Tid'] = pd.to_datetime(target_2022['Dato/Tid'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking for missing data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dato/Tid          False\n",
       "Volum             False\n",
       "Solskinstid       False\n",
       "Lufttemperatur     True\n",
       "Vindstyrke         True\n",
       "Måned             False\n",
       "Dag               False\n",
       "Ukedag            False\n",
       "Time              False\n",
       "Måned_1           False\n",
       "Måned_10          False\n",
       "Måned_11          False\n",
       "Måned_12          False\n",
       "Måned_2           False\n",
       "Måned_3           False\n",
       "Måned_4           False\n",
       "Måned_5           False\n",
       "Måned_6           False\n",
       "Måned_7           False\n",
       "Måned_8           False\n",
       "Måned_9           False\n",
       "Ukedag_0          False\n",
       "Ukedag_1          False\n",
       "Ukedag_2          False\n",
       "Ukedag_3          False\n",
       "Ukedag_4          False\n",
       "Ukedag_5          False\n",
       "Ukedag_6          False\n",
       "Time_0            False\n",
       "Time_1            False\n",
       "Time_10           False\n",
       "Time_11           False\n",
       "Time_12           False\n",
       "Time_13           False\n",
       "Time_14           False\n",
       "Time_15           False\n",
       "Time_16           False\n",
       "Time_17           False\n",
       "Time_18           False\n",
       "Time_19           False\n",
       "Time_2            False\n",
       "Time_20           False\n",
       "Time_21           False\n",
       "Time_22           False\n",
       "Time_23           False\n",
       "Time_3            False\n",
       "Time_4            False\n",
       "Time_5            False\n",
       "Time_6            False\n",
       "Time_7            False\n",
       "Time_8            False\n",
       "Time_9            False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for lost data using boolean values\n",
    "data_train.isnull().any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have missing data, which is to be expected. We will impute this during modelling shortly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dato/Tid</th>\n",
       "      <th>Volum</th>\n",
       "      <th>Solskinstid</th>\n",
       "      <th>Lufttemperatur</th>\n",
       "      <th>Vindstyrke</th>\n",
       "      <th>Måned</th>\n",
       "      <th>Dag</th>\n",
       "      <th>Ukedag</th>\n",
       "      <th>Time</th>\n",
       "      <th>Måned_1</th>\n",
       "      <th>...</th>\n",
       "      <th>Time_21</th>\n",
       "      <th>Time_22</th>\n",
       "      <th>Time_23</th>\n",
       "      <th>Time_3</th>\n",
       "      <th>Time_4</th>\n",
       "      <th>Time_5</th>\n",
       "      <th>Time_6</th>\n",
       "      <th>Time_7</th>\n",
       "      <th>Time_8</th>\n",
       "      <th>Time_9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-07-16 17:00:00</td>\n",
       "      <td>84</td>\n",
       "      <td>60.0</td>\n",
       "      <td>13.866667</td>\n",
       "      <td>3.933333</td>\n",
       "      <td>7</td>\n",
       "      <td>16</td>\n",
       "      <td>3</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-07-16 18:00:00</td>\n",
       "      <td>57</td>\n",
       "      <td>60.0</td>\n",
       "      <td>13.216667</td>\n",
       "      <td>4.233333</td>\n",
       "      <td>7</td>\n",
       "      <td>16</td>\n",
       "      <td>3</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-07-16 19:00:00</td>\n",
       "      <td>49</td>\n",
       "      <td>60.0</td>\n",
       "      <td>12.683333</td>\n",
       "      <td>2.950000</td>\n",
       "      <td>7</td>\n",
       "      <td>16</td>\n",
       "      <td>3</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-07-16 20:00:00</td>\n",
       "      <td>45</td>\n",
       "      <td>36.0</td>\n",
       "      <td>12.066667</td>\n",
       "      <td>2.483333</td>\n",
       "      <td>7</td>\n",
       "      <td>16</td>\n",
       "      <td>3</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-07-16 21:00:00</td>\n",
       "      <td>25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.350000</td>\n",
       "      <td>1.083333</td>\n",
       "      <td>7</td>\n",
       "      <td>16</td>\n",
       "      <td>3</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45104</th>\n",
       "      <td>2021-12-31 16:00:00</td>\n",
       "      <td>7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.600000</td>\n",
       "      <td>1.033333</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>4</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45105</th>\n",
       "      <td>2021-12-31 18:00:00</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.483333</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>4</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45106</th>\n",
       "      <td>2021-12-31 19:00:00</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.616667</td>\n",
       "      <td>2.650000</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>4</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45107</th>\n",
       "      <td>2021-12-31 20:00:00</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.700000</td>\n",
       "      <td>1.916667</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>4</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45108</th>\n",
       "      <td>2021-12-31 21:00:00</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.233333</td>\n",
       "      <td>1.733333</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>4</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>45109 rows × 52 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Dato/Tid  Volum  Solskinstid  Lufttemperatur  Vindstyrke  \\\n",
       "0     2015-07-16 17:00:00     84         60.0       13.866667    3.933333   \n",
       "1     2015-07-16 18:00:00     57         60.0       13.216667    4.233333   \n",
       "2     2015-07-16 19:00:00     49         60.0       12.683333    2.950000   \n",
       "3     2015-07-16 20:00:00     45         36.0       12.066667    2.483333   \n",
       "4     2015-07-16 21:00:00     25          0.0       11.350000    1.083333   \n",
       "...                   ...    ...          ...             ...         ...   \n",
       "45104 2021-12-31 16:00:00      7          0.0        6.600000    1.033333   \n",
       "45105 2021-12-31 18:00:00      5          0.0        6.483333    0.466667   \n",
       "45106 2021-12-31 19:00:00      4          0.0        5.616667    2.650000   \n",
       "45107 2021-12-31 20:00:00      2          0.0        4.700000    1.916667   \n",
       "45108 2021-12-31 21:00:00      5          0.0        4.233333    1.733333   \n",
       "\n",
       "       Måned  Dag  Ukedag  Time  Måned_1  ...  Time_21  Time_22  Time_23  \\\n",
       "0          7   16       3    17        0  ...        0        0        0   \n",
       "1          7   16       3    18        0  ...        0        0        0   \n",
       "2          7   16       3    19        0  ...        0        0        0   \n",
       "3          7   16       3    20        0  ...        0        0        0   \n",
       "4          7   16       3    21        0  ...        1        0        0   \n",
       "...      ...  ...     ...   ...      ...  ...      ...      ...      ...   \n",
       "45104     12   31       4    16        0  ...        0        0        0   \n",
       "45105     12   31       4    18        0  ...        0        0        0   \n",
       "45106     12   31       4    19        0  ...        0        0        0   \n",
       "45107     12   31       4    20        0  ...        0        0        0   \n",
       "45108     12   31       4    21        0  ...        1        0        0   \n",
       "\n",
       "       Time_3  Time_4  Time_5  Time_6  Time_7  Time_8  Time_9  \n",
       "0           0       0       0       0       0       0       0  \n",
       "1           0       0       0       0       0       0       0  \n",
       "2           0       0       0       0       0       0       0  \n",
       "3           0       0       0       0       0       0       0  \n",
       "4           0       0       0       0       0       0       0  \n",
       "...       ...     ...     ...     ...     ...     ...     ...  \n",
       "45104       0       0       0       0       0       0       0  \n",
       "45105       0       0       0       0       0       0       0  \n",
       "45106       0       0       0       0       0       0       0  \n",
       "45107       0       0       0       0       0       0       0  \n",
       "45108       0       0       0       0       0       0       0  \n",
       "\n",
       "[45109 rows x 52 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Overview of training data\n",
    "data_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now need to find the best model for our data in order to create a prediction. We can start by splitting our data into x and y variables. The x variable will be the weather conditions (subject to change), and the dummy variables for the time. The y variable will be the quantity (volum) of the bikes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Years are not periodical, so we won't predict on them\n",
    "# We convert to numpy too, as the models may not work on dataframe objects\n",
    "X_train = data_train.drop(['Dato/Tid', 'Volum'], axis=1).to_numpy()\n",
    "y_train = data_train['Volum'].to_numpy()\n",
    "\n",
    "X_val = data_val.drop(['Dato/Tid', 'Volum'], axis=1).to_numpy()\n",
    "y_val = data_val['Volum'].to_numpy()\n",
    "\n",
    "X_test = data_test.drop(['Dato/Tid', 'Volum'], axis=1).to_numpy()\n",
    "y_test = data_test['Volum'].to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are different ways to model data. We have classification, regression, cluster analysis, and hypothesis testing.\n",
    "We don't need to classify data into categories, cluster data into certain characteristics, or test a hypothesis for the data. We are attempting to create a prediction for future data, so regression seems to be the optimal choice. Now, we need to pick the best possible regression model for our data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We fit our model on training data, and create a prediction on validation data. We will pick out the best model to run on test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE_baseline:  71.57\n"
     ]
    }
   ],
   "source": [
    "# Mean is a decent strategy, as data can vary. It also gave a better RMSE score than median\n",
    "baseline = DummyRegressor(strategy='mean')\n",
    "baseline.fit(X_train, y_train)\n",
    "baseline_prediction = baseline.predict(X_val)\n",
    "\n",
    "print('RMSE_baseline: ', np.round(np.sqrt(mean_squared_error(y_val, baseline_prediction)), decimals=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above block of code, we started off with creating a baseline model to compare with. We want to get an RMSE (root mean-squared error) value less than the baseline and as close as possible to 0. This helps us to compare the accuracy of our actual models. Otherwise, the RMSE value won't tell us much about how good the model is. The RMSE value tells us the difference in values between predicted and actual values, which differs depending on the characteristics of the data (a dataset with higher values and higher variance is more likely to have a higher RMSE value). The ideal thing to do now is experiment with various regression models and pick out the best one.\n",
    "\n",
    "It's hard to say what results I expect, as I'm quite inexperienced with many of these models and machine learning in general. I reckon that models such as k-neighbours regression may end up being good, as it predicts values based on other values in a given neighbourhood. Polynomial model also has potential, as you can apply various degrees to create a good fit. We will have to find the sweet spot for that. As I have many independent variables, a more complex model could also be good, but I will have to experiment with a few."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now impute our missing data. Our data seems to be missing at random (MAR), as sometimes, our data usually goes missing in chunks (a given timeframe). For instance, if you look at the weather data for 20 May 2016, there is a chunk of missing data. I assume the reason is that equipment for recording data may have been faulty or under maintenance during that time. If you have MAR, then it is good to use k-neighbours imputation. A value 9 is ideal as values beyond that could vary by much more, also, it seems to work best for all models when I graphed it, so this is what I will pick. I could use IterativeImputer, but the share of missing data is quite small, and it is unlikely to significantly change the prediction. With SimpleImputer, I can impute with mean or median, which isn't ideal due to the variance of the data and the periodical nature of it (Eg: not ideal to impute missing data for sunshine time with its median, especially if it is during nighttime). K-neighbours imputation is also good if multiple variables have missing data (true in our case).\n",
    "\n",
    "As for scaling, I can pick between StandardScaler, and MinMaxScaler. StandardScaler scales values based on the standard normal distribution, while MinMaxScaler scales values between 0 and 1. I will choose to scale values via MinMaxScaler(). This will help optimise our model, especially when you consider that the dummy variables go from 0 to 1 as well. Also, I did graph some of these models, but I won't include these graphs as they take a long time to run.\n",
    "\n",
    "Finally, for most of these models, I did graph them with degrees 1 to 300, picking out the best one, but these graphs take extremely long to run, so I won't include them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear regression is very simple. We predict the value of a variable based on another. We assume that this relationship between the two sets of variables is linear, making use of linear equations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE_linear_regression:  43.12\n"
     ]
    }
   ],
   "source": [
    "# We can include the imputer and the scaler in the make_pipeline() method along with the regression model in order to fit and transform automatically\n",
    "lr = make_pipeline(KNNImputer(n_neighbors=9), MinMaxScaler(), LinearRegression())\n",
    "lr.fit(X_train, y_train)\n",
    "lr_prediction = lr.predict(X_val)\n",
    "\n",
    "print('RMSE_linear_regression: ', np.round(np.sqrt(mean_squared_error(y_val, lr_prediction)), decimals=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Polynomial regression uses the relationship between the x and y variables to create a model of the nth degree. So, it is like linear regression, but we add polynomial terms (higher-degree terms such as x^2, with x being a variable), in order to predict in a different way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE_polynomial:  27.86\n"
     ]
    }
   ],
   "source": [
    "# I choose a degree of 2 as choosing a larger value causes this to crash\n",
    "polynomial_model = make_pipeline(KNNImputer(n_neighbors=9), MinMaxScaler(), PolynomialFeatures(degree=2), LinearRegression())\n",
    "polynomial_model.fit(X_train, y_train)\n",
    "polynomial_prediction = polynomial_model.predict(X_val)\n",
    "\n",
    "print('RMSE_polynomial: ', np.round(np.sqrt(mean_squared_error(y_val, polynomial_prediction)), decimals=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lasso regression is a form of linear regression that makes use of a method called shrinkage. This is when values are \"shrunk\" towards a central point, such as the mean or the median. This is mostly ideal for models with fewer variables, so it may not work so well with our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE_lasso:  48.25\n"
     ]
    }
   ],
   "source": [
    "lasso_model = make_pipeline(KNNImputer(n_neighbors=9), MinMaxScaler(), Lasso(1))\n",
    "lasso_model.fit(X_train, y_train)\n",
    "lasso_prediction = lasso_model.predict(X_val)\n",
    "print('RMSE_lasso: ', np.round(np.sqrt(mean_squared_error(y_val, lasso_prediction)), decimals=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Elastic Net regression combines Lasso regression and Ridge regression by using both penalties from those models. It is an improved version of both models, but I get a better RMSE for Lasso regression above, interestingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE_elastic_net:  66.55\n"
     ]
    }
   ],
   "source": [
    "elasticnet_model = make_pipeline(KNNImputer(n_neighbors=9), MinMaxScaler(), ElasticNet(1))\n",
    "elasticnet_model.fit(X_train, y_train)\n",
    "elastic_net_prediction = elasticnet_model.predict(X_val)\n",
    "\n",
    "print('RMSE_elastic_net: ', np.round(np.sqrt(mean_squared_error(y_val, elastic_net_prediction)), decimals=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "K-neighbours regression is pretty self-explanatory. It approximates the relationship between the variables and the outcomes by averaging values in the given neighbourhood of size n. This is also less ideal for multiple variables, but we do get a decent RMSE score nonetheless."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE_k_neighbors:  28.78\n"
     ]
    }
   ],
   "source": [
    "kneighbors_model = make_pipeline(KNNImputer(n_neighbors=9), MinMaxScaler(), KNeighborsRegressor(7))\n",
    "kneighbors_model.fit(X_train, y_train)\n",
    "kneighbors_prediction = kneighbors_model.predict(X_val)\n",
    "\n",
    "print('RMSE_k_neighbors: ', np.round(np.sqrt(mean_squared_error(y_val, kneighbors_prediction)), decimals=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random forest regression makes use of ensemble learning and bootstrapping to create multiple decision trees. Ensemble learning involves multiple models, training them over our data, and taking the average to find an improved result. Bootstrapping involves creating random samples of the data, and averaging them (I assume this is why the RMSE varies everytime I run it). Combining this with decision trees, we get this model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE_forest:  24.29\n"
     ]
    }
   ],
   "source": [
    "# I tried to graph parameters for this (1 to 300), but it was running for over 1 hour, so I picked values via trial and error\n",
    "# Having the default parameter of 100 works well enough, especially when it varies every time I run it\n",
    "forest_model = make_pipeline(KNNImputer(n_neighbors=9), MinMaxScaler(), RandomForestRegressor())\n",
    "forest_model.fit(X_train, y_train)\n",
    "forest_prediction = forest_model.predict(X_val)\n",
    "print('RMSE_forest: ', np.round(np.sqrt(mean_squared_error(y_val, forest_prediction)), decimals=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decision tree involves breaking down data into smaller subsets, turning them into trees (like following a path). It does not take in numerical parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE_decision_tree:  32.48\n"
     ]
    }
   ],
   "source": [
    "dt_model = make_pipeline(KNNImputer(n_neighbors=9), MinMaxScaler(), DecisionTreeRegressor())\n",
    "dt_model.fit(X_train, y_train)\n",
    "dt_prediction = dt_model.predict(X_val)\n",
    "\n",
    "print('RMSE_decision_tree: ', np.round(np.sqrt(mean_squared_error(y_val, dt_prediction)), decimals=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have run through 6 models, and the one with the lowest RMSE score is the random forest model with a degree of 100 (default). Now, we can check how well it fits with the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE_test:  23.54\n"
     ]
    }
   ],
   "source": [
    "prediction_test = forest_model.predict(X_test)\n",
    "\n",
    "print('RMSE_test: ', np.round(np.sqrt(mean_squared_error(y_test, prediction_test)), decimals=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This value seems to be a decent fit, especially when we compare with the baseline. We now have to apply this onto 2022 data, given in the target_2022 CSV file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting 2022 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# As the 2022 data does not have all months, I need to add the remaining dummy variables so it matches with the training data. I can pad these with 0s\n",
    "extra_months = ['Måned_10', 'Måned_11', 'Måned_12', 'Måned_6', 'Måned_7', 'Måned_8', 'Måned_9']\n",
    "\n",
    "for col in extra_months:\n",
    "    target_2022[col] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The columns need to be in the correct order, otherwise the model won't work well\n",
    "# We also add a Volum column and pad them with 0s\n",
    "target_2022['Volum'] = 0\n",
    "target_2022 = target_2022[data_train.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the corresponding columns\n",
    "target_x = target_2022.drop(['Dato/Tid', 'Volum'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3.85, 1.67, 1.38, ..., 6.51, 4.56, 1.62])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Array of predicted values\n",
    "volum_2022 = forest_model.predict(target_x.to_numpy())\n",
    "volum_2022"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dato/Tid</th>\n",
       "      <th>Volum</th>\n",
       "      <th>Solskinstid</th>\n",
       "      <th>Lufttemperatur</th>\n",
       "      <th>Vindstyrke</th>\n",
       "      <th>Måned</th>\n",
       "      <th>Dag</th>\n",
       "      <th>Ukedag</th>\n",
       "      <th>Time</th>\n",
       "      <th>Måned_1</th>\n",
       "      <th>...</th>\n",
       "      <th>Time_21</th>\n",
       "      <th>Time_22</th>\n",
       "      <th>Time_23</th>\n",
       "      <th>Time_3</th>\n",
       "      <th>Time_4</th>\n",
       "      <th>Time_5</th>\n",
       "      <th>Time_6</th>\n",
       "      <th>Time_7</th>\n",
       "      <th>Time_8</th>\n",
       "      <th>Time_9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-01-01 00:00:00</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.016667</td>\n",
       "      <td>0.683333</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-01-01 01:00:00</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>1.233333</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-01-01 02:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.316667</td>\n",
       "      <td>1.233333</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-01-01 03:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.733333</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-01-01 04:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.100000</td>\n",
       "      <td>0.950000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3550</th>\n",
       "      <td>2022-05-28 22:00:00</td>\n",
       "      <td>26</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.450000</td>\n",
       "      <td>4.983333</td>\n",
       "      <td>5</td>\n",
       "      <td>28</td>\n",
       "      <td>5</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3551</th>\n",
       "      <td>2022-05-28 23:00:00</td>\n",
       "      <td>20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.133333</td>\n",
       "      <td>5.050000</td>\n",
       "      <td>5</td>\n",
       "      <td>28</td>\n",
       "      <td>5</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3552</th>\n",
       "      <td>2022-05-29 00:00:00</td>\n",
       "      <td>7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.016667</td>\n",
       "      <td>4.566667</td>\n",
       "      <td>5</td>\n",
       "      <td>29</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3553</th>\n",
       "      <td>2022-05-29 01:00:00</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.816667</td>\n",
       "      <td>3.533333</td>\n",
       "      <td>5</td>\n",
       "      <td>29</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3554</th>\n",
       "      <td>2022-05-29 02:00:00</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.733333</td>\n",
       "      <td>3.866667</td>\n",
       "      <td>5</td>\n",
       "      <td>29</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3555 rows × 52 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Dato/Tid  Volum  Solskinstid  Lufttemperatur  Vindstyrke  \\\n",
       "0    2022-01-01 00:00:00      4          0.0        3.016667    0.683333   \n",
       "1    2022-01-01 01:00:00      2          0.0        2.666667    1.233333   \n",
       "2    2022-01-01 02:00:00      1          0.0        2.316667    1.233333   \n",
       "3    2022-01-01 03:00:00      1          0.0        1.733333    0.900000   \n",
       "4    2022-01-01 04:00:00      1          0.0        1.100000    0.950000   \n",
       "...                  ...    ...          ...             ...         ...   \n",
       "3550 2022-05-28 22:00:00     26          0.0        7.450000    4.983333   \n",
       "3551 2022-05-28 23:00:00     20          0.0        7.133333    5.050000   \n",
       "3552 2022-05-29 00:00:00      7          0.0        7.016667    4.566667   \n",
       "3553 2022-05-29 01:00:00      5          0.0        6.816667    3.533333   \n",
       "3554 2022-05-29 02:00:00      2          0.0        6.733333    3.866667   \n",
       "\n",
       "      Måned  Dag  Ukedag  Time  Måned_1  ...  Time_21  Time_22  Time_23  \\\n",
       "0         1    1       5     0        1  ...        0        0        0   \n",
       "1         1    1       5     1        1  ...        0        0        0   \n",
       "2         1    1       5     2        1  ...        0        0        0   \n",
       "3         1    1       5     3        1  ...        0        0        0   \n",
       "4         1    1       5     4        1  ...        0        0        0   \n",
       "...     ...  ...     ...   ...      ...  ...      ...      ...      ...   \n",
       "3550      5   28       5    22        0  ...        0        1        0   \n",
       "3551      5   28       5    23        0  ...        0        0        1   \n",
       "3552      5   29       6     0        0  ...        0        0        0   \n",
       "3553      5   29       6     1        0  ...        0        0        0   \n",
       "3554      5   29       6     2        0  ...        0        0        0   \n",
       "\n",
       "      Time_3  Time_4  Time_5  Time_6  Time_7  Time_8  Time_9  \n",
       "0          0       0       0       0       0       0       0  \n",
       "1          0       0       0       0       0       0       0  \n",
       "2          0       0       0       0       0       0       0  \n",
       "3          1       0       0       0       0       0       0  \n",
       "4          0       1       0       0       0       0       0  \n",
       "...      ...     ...     ...     ...     ...     ...     ...  \n",
       "3550       0       0       0       0       0       0       0  \n",
       "3551       0       0       0       0       0       0       0  \n",
       "3552       0       0       0       0       0       0       0  \n",
       "3553       0       0       0       0       0       0       0  \n",
       "3554       0       0       0       0       0       0       0  \n",
       "\n",
       "[3555 rows x 52 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Input the values and round them\n",
    "target_2022['Volum'] = volum_2022\n",
    "target_2022 = target_2022.round({'Volum': 0})\n",
    "target_2022['Volum'] = target_2022['Volum'].astype(int)\n",
    "\n",
    "# Replace potential negative values with 0\n",
    "target_2022.Volum = np.where(target_2022.Volum < 0, 0, target_2022.Volum)\n",
    "target_2022"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can save this to a CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_2022.to_csv('predictions.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving the model for the creation of a website"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to display our model in a website, and we can do that in app.py. We first need to store this model using the pickle library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pickle.dump(forest_model, open('model.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the end, we managed to get a good RMSE score, easily beating the baseline, and we managed to display results for the 2022 data. This concludes the data science process. The trickiest parts were preparing the data, namely organising the rows into hourly data, setting up date and time, and merging the data. Picking the right model, along with the correct data points was a challenge as well, especially since I would get varying RMSE values for the columns that I selected. For instance, including the individual date and time columns, even though it makes little sense to include this, as these values are scaled. This was a surprise, but I may have been wrong about the scaled date and time columns.\n",
    "\n",
    "It was also frustrating that I couldn't do higher degree polynomial regression, as the number of columns was limited by computational resources. It was also annoying when I had to make graphs that ran for 5+ minutes in order to select the best RMSE values for various regression models (60+ minutes for random forest regression). As for variable extraction, I did also attempt to extract whether it was a weekend or not (1 if yes, 0 if not), but that didn't improve my RMSE, so I discarded it. I also had dummy variables for each day of the month, but removing these improved my RMSE, interestingly. So I logically discarded it.\n",
    "\n",
    "It would be nice to have extra data, so I could find out why there is a dip in the volum during the middle of summer. If I had to guess, I suspect it has to do with people going on vacation, and many cyclists bike to work. I can't know for sure though. It would also be nice to have precipitation data, which I reckon would be the best predictor of bike traffic.\n",
    "If I had unlimited time, I would try to get data on precipitation or other factors, and make use of that. I would also attempt to play around with more regression methods to get an improved RMSE score.\n",
    "\n",
    "The figures gave me a good understanding of how volum correlated with the weather conditions. I also learned about the characteristics of the data, especially when taking a closer look. I could have included a more diverse range of figures, but I felt that I got a good insight from the ones I made. I wish I could've plotted multiple lines on the same graph, so that it is easier to compare. Unfortunately, due to the different scales, this was not possible, and plotly did not allow for multiple axes.\n",
    "\n",
    "I wasn't surprised by how well random forest regression worked, considering the scale of ensemble models. It was a complex model in that it takes decision trees and uses more algorithms to create another regression model, so it met expectations in that sense.\n",
    "\n",
    "Ultimately, this was a valuable introduction to large-scale data science and a good learning experience to take forward in future projects."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 64-bit (microsoft store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e0a79c76574919354e3ac5f8de62c0c23dfecd089a514de40db9df7886111055"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
